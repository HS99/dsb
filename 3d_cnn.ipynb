{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 980M (CNMeM is enabled with initial size: 90.0% of memory, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "import tensorflow as tf\n",
    "from scipy.misc import toimage, imresize\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Convolution2D, Flatten, BatchNormalization, Convolution3D\n",
    "from keras.layers import Activation, MaxPooling2D, UpSampling2D, Lambda, MaxPooling3D, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMG_SIZE_PX = 256\n",
    "SLICE_COUNT = 64\n",
    "\n",
    "n_classes = 2\n",
    "\n",
    "keep_rate = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_array(path, arr):\n",
    "    np.save(path, arr)\n",
    "    \n",
    "\n",
    "def load_array(path):\n",
    "    return np.load(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load ids for training and validation sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0030a160d58723ff36d73f41b170ec21', '003f41c78e6acfa92430a057ac0b306e', '0092c13f9e00a3717fdc940641f00015']\n",
      "['0015ceb851d7251b8f399e39779d1e7d', '006b96310a37b36cccb2ab48d10b49a3', '008464bb8521d09a42985dd8add3d0d2']\n",
      "['026470d51482c93efc18b9803159c960', '031b7ec4fe96a3b035a8196264a8c8c3', '03bd22ed5858039af223c04993e9eb22']\n"
     ]
    }
   ],
   "source": [
    "train_ids = [id.replace(\".npy\", \"\") for id in os.listdir('prepd_stage1/train/')]\n",
    "valid_ids = [id.replace(\".npy\", \"\") for id in os.listdir('prepd_stage1/valid/')]\n",
    "test_ids = [id.replace(\".npy\", \"\") for id in os.listdir('prepd_stage1/test/')]\n",
    "\n",
    "train_ids.sort()\n",
    "valid_ids.sort()\n",
    "test_ids.sort()\n",
    "\n",
    "print(train_ids[:3])\n",
    "print(valid_ids[:3])\n",
    "print(test_ids[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load ground-truth labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cancer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0015ceb851d7251b8f399e39779d1e7d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0030a160d58723ff36d73f41b170ec21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003f41c78e6acfa92430a057ac0b306e</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>006b96310a37b36cccb2ab48d10b49a3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>008464bb8521d09a42985dd8add3d0d2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  cancer\n",
       "0  0015ceb851d7251b8f399e39779d1e7d       1\n",
       "1  0030a160d58723ff36d73f41b170ec21       0\n",
       "2  003f41c78e6acfa92430a057ac0b306e       0\n",
       "3  006b96310a37b36cccb2ab48d10b49a3       1\n",
       "4  008464bb8521d09a42985dd8add3d0d2       1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('metadata/stage1_labels.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0]\n",
      "[1 1 1]\n"
     ]
    }
   ],
   "source": [
    "train_labels = df[\"cancer\"][df[\"id\"].isin(train_ids)].values\n",
    "valid_labels = df[\"cancer\"][df[\"id\"].isin(valid_ids)].values\n",
    "\n",
    "print(train_labels[:3])\n",
    "print(valid_labels[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generators for loading preprocessed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_slices = 32\n",
    "\n",
    "def get_train_batches():\n",
    "\n",
    "    for ix, patient in enumerate(train_ids):\n",
    "        sample = load_array(\"prepd_stage1/train/{}.npy\".format(patient))\n",
    "        sample = np.array([imresize(toimage(im), size=(IMG_SIZE_PX, IMG_SIZE_PX)) for im in sample])\n",
    "        \n",
    "        ht = sample.shape[0]\n",
    "        bottom = int(np.floor((ht - SLICE_COUNT)/2))\n",
    "        top = int(np.floor((ht + SLICE_COUNT)/2))\n",
    "        \n",
    "        # plt.imshow(sample[100], cmap=\"gray\")\n",
    "        \n",
    "        try:\n",
    "            sample = np.array([sample[bottom:top, :, :].reshape(1, SLICE_COUNT, IMG_SIZE_PX, IMG_SIZE_PX)])\n",
    "            label = np.array([train_labels[ix]])    \n",
    "            yield sample, label\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(patient, e, sample.shape)\n",
    "            continue\n",
    "\n",
    "            \n",
    "def get_valid_batches():\n",
    "    for ix, patient in enumerate(valid_ids):\n",
    "        sample = load_array(\"prepd_stage1/valid/{}.npy\".format(patient))\n",
    "        \n",
    "        sample = np.array([imresize(toimage(im), size=(IMG_SIZE_PX, IMG_SIZE_PX)) for im in sample])\n",
    "        \n",
    "        ht = sample.shape[0]\n",
    "        bottom = int(np.floor((ht - SLICE_COUNT)/2))\n",
    "        top = int(np.floor((ht + SLICE_COUNT)/2))\n",
    "        \n",
    "        try:\n",
    "            sample = np.array([sample[bottom:top, :, :].reshape(1, SLICE_COUNT, IMG_SIZE_PX, IMG_SIZE_PX)])\n",
    "            label = np.array([valid_labels[ix]])\n",
    "            yield sample, label\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(patient, e, sample.shape)\n",
    "            continue\n",
    "            \n",
    "            \n",
    "def get_test_batches():\n",
    "    for ix, patient in enumerate(test_ids):\n",
    "        sample = load_array(\"prepd_stage1/test/{}.npy\".format(patient))\n",
    "        \n",
    "        sample = np.array([imresize(toimage(im), size=(IMG_SIZE_PX, IMG_SIZE_PX)) for im in sample])\n",
    "        \n",
    "        ht = sample.shape[0]\n",
    "        bottom = int(np.floor((ht - SLICE_COUNT)/2))\n",
    "        top = int(np.floor((ht + SLICE_COUNT)/2))\n",
    "        \n",
    "        try:\n",
    "            sample = np.array([sample[bottom:top, :, :].reshape(1, SLICE_COUNT, IMG_SIZE_PX, IMG_SIZE_PX)])\n",
    "            yield sample\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(patient, e, sample.shape)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# gen = get_train_batches()\n",
    "\n",
    "# for x, y in gen:\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution3D(32, 7, 7, 7, activation='tanh', border_mode='same', input_shape=(1, SLICE_COUNT, IMG_SIZE_PX, IMG_SIZE_PX)))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), border_mode='same'))\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Convolution3D(64, 7, 7, 7, activation='tanh', border_mode='same'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), border_mode='same'))\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='tanh'))\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "optim = Adam(lr=.01)\n",
    "model.compile(optimizer=optim, loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 of 15...\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "\n",
    "for e in range(epochs):\n",
    "    print(\"\\nEpoch {0} of {1}...\".format(e+1, epochs))\n",
    "    trn_gen = get_train_batches()\n",
    "    val_gen = get_valid_batches()\n",
    "\n",
    "    for X, y in trn_gen:\n",
    "        model.train_on_batch(X, y)\n",
    "        \n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for X, y in val_gen:\n",
    "        prediction = model.predict(X, verbose=0)\n",
    "        y_true.append(y[0])\n",
    "        y_pred.append(prediction[0])\n",
    "\n",
    "    print(\"Val Loss:\", log_loss(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"3d_v1.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_gen = get_test_batches()\n",
    "\n",
    "test_x = np.array([x for x in test_gen])\n",
    "test_x = np.vstack(test_x)\n",
    "\n",
    "test_x[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"submissions/stage1_sample_submission.csv\")\n",
    "\n",
    "# preds = np.clip(model.predict(test_x), 0.001, 1)\n",
    "# df['cancer'] = preds\n",
    "\n",
    "# df.to_csv('submissions/-LB_3d.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
